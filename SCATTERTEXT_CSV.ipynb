{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import string \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('c:/Users/Administrador/Downloads/Dataset_eventos/CORPUS.csv', encoding='utf8')# Datos en csv\n",
    "\n",
    "path='c:/Users/Administrador/Downloads/Dataset_eventos/' #Ruta para guardar los archivos en html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccionar columna de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Antel, OSE, UTE, la iglesia Anglicana, las org...\n",
       "1       Antel, OSE, UTE, la iglesia Anglicana, las org...\n",
       "2       l director de Salud de la intendencia, Mi g u ...\n",
       "3       l director de Salud de la intendencia, Mi g u ...\n",
       "4       l director de Salud de la intendencia, Mi g u ...\n",
       "                              ...                        \n",
       "1524        ?Sacrificio de perros con leishmaniasis es lo\n",
       "1525    ?Salud Pública confirmó caso de leishmaniasis ...\n",
       "1526    ?Se confirmó el segundo caso de Leishmaniasis ...\n",
       "1527    ?Se suspendió el estado de emergencia sanitari...\n",
       "1528    ?Sostienen que el MSP realiza un “exterminio” ...\n",
       "Name: Text, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "df['Text']=df['Text'].apply(str) #Convierte el texto en dato de tipo string\n",
    "\n",
    "def clean_text(Text):\n",
    "  Text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', Text, flags=re.MULTILINE) #Elimina las url\n",
    "  Text = re.sub(r'#', '', Text) #Elimina los #\n",
    "  Text= re.sub(r'[0-9]+', '', str(Text)) #Elimina números\n",
    "  Text = re.sub(r'@[A-Za-z0-9]+', '', Text)#Elimina nombres de usuarios\n",
    "  Text = re.sub('\\[[^]]*\\]', '', Text) #Elmina los []\n",
    "  Text = re.sub(r'\\s+', ' ',   Text) #Elimina los dobles espacios en blanco\n",
    "  Text = re.sub(r'<[^>]*?>', '', Text) # Eliminar caracteres HTML\n",
    "  Text = re.sub(r'[^\\w\\s]', ' ', Text) # Eliminar puntuación\n",
    "  #Text = ''.join(re.findall('[A-Z][^A-Z]*', Text)) # Separar palabras pegadas\n",
    "  Text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(Text)) #Estandarizar palabras\n",
    "  Text = Text.lower() #Normalizar palabras a minusculas\n",
    "  Text= lancaster.stem(Text) #Lemantizar palabras\n",
    "  Text= re.split(r'\\W+', Text)# dividir texto en palabras\n",
    "\n",
    " \n",
    "  return Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (iglesia, anglicana, organizaciones, gubername...\n",
       "1       (iglesia, anglicana, organizaciones, gubername...\n",
       "2       (director, salud, intendencia, personas, refug...\n",
       "3       (director, salud, intendencia, personas, refug...\n",
       "4       (director, salud, intendencia, personas, refug...\n",
       "                              ...                        \n",
       "1524                                 (sacrificio, perros)\n",
       "1525           (salud, pública, confirmó, visceral, niño)\n",
       "1526                        (confirmó, segundo, visceral)\n",
       "1527                   (suspendió, emergencia, sanitaria)\n",
       "1528      (sostienen, msp, exterminio, perros, respuesta)\n",
       "Name: parsed, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['Text'].apply(clean_text)# Aplica los cambios efectuados en la limpieza del texto\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# palabras adicionales que no se requieran considerar\n",
    "agregar = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'ñ', 'o', 'p', 'q', 'r', 's','t', 'u', 'v', 'w', 'x', 'y', 'z', '1', 'pr', 'án', 'ó', 'uy', '1 1', '11', 'tr', '200', 'í', '5', 'as', 'mm', 'és', 'má', '00', '0 0', 'ú', '15', '0', 'vi', '5', 'númer', 'atur', 'entr', 'co', 'á', 'par', '1212', 'tod', 'ww', '6', 'das', 'á', 'é', 'í', 'ó', 'ú', \n",
    "           'ándezgaleano', 'ose', 'antel', 'habí', 'ejércit', 'mañ hoy', 'dor', 'émicas', 'aseguró', 'dr', 'vacudas', 'bayardi', 'consejos', 'perdido', 'van', 'im', 'parar', 'ute', 'josé', 'sigue', 'paí', 'fenó', 'mañ', 'permite', 'presió', 'ca', 'éstas', 'br', 'ele', 'éstas', 'caí', 'guichó', 'alturí', 'ómetro', 'jinetes', 'cayeron', 'du', 'paso', 'cubre', 'º º', 'kw', 'dí', 'ma', 'fr', 'situació', 'autóctono', 'logra', 'acabar', 'salto', 'leishmaniasis', 'todas', 'ández', 'antel', 'jógaleano', 'acuer', 'así', 'dos', 'do', 'pou', 'total', 'on', 'según', 'temper', 'ísir', 'kw', 'siendo', 'da', 'ío', 'paysandú', 'informó', 'ºc', 'ser', 'ar', 'fin', 'gr', 'uc', 'https', 'norte', 'siendo', 'ar', 'du', 'caí', 'galeano', 'habí', 'viven', 'tot', 'arr', 'cu', 'obr', 'nueve mañ', 'florid', 'paliar', 'azotó', 'web', 'astr', 'ecr', 'ine', 'ex', 'nal', 'puntas ser', 'ológicas encuentr', 'den egiones', 'hombr', 'deo', 'saldo', 'poca', 'cost', 'altu', 'temporal tambié', 'crece', 'quedan', 'accuweather', 'by', 'ops', 'só', 'caí', 'caí du', 'aun', 'ed', 'mer', 'ele', 'po', 'mil', 'yí', 'dejó', 'íneas', 'ahor', 'fuer', 'ár', 'ximos', 'jue', 'com', 'todas', 'emitió', 'dijo', 'ola', 'anizo', 'cortos', 'emer', 'kolómetr', 'nuevas', 'cosas', 'participó', 'casos', 'hizo', 'ador', 'mu', 'érmicas', 'hoy secretario', 'educacioó', 'sar', 'hizo', 'ón', 'dur', 'dijo', 'queguay', 'ís', 'ir', 'ología', 'an', 'esper', 'rí', 'queguay durazno', 'tambié', 'íz', 'dan', 'fa', 'egistr', 'inumet', 'º', 'di', 'cota', 'mu', 'amas', 'enciso', 'dió', 'arias', 'gas', 'tapi', 'rea', 'et', 'tã', 'óximas', 'ena', 'quedó cinco', 'sábado xtendiéndose', 'cando', 'xtr', 'pn', 'dar otr', 'xiste', 'difer', 'is', 'pit', 'debió', 'yos', 'hizo', 'qu', 've', 'fa', 'dan', 'toda', 'ondar', 'sina', 'anizo', 'rige', 'podr', 'educació', 'destacó', 'mas', 'egr', 'río', 'er', 'caída', 'ingr', 'destacó', 'contó', 'fugios', 'montevi representan', 'ruta kiló', 'ecos', 'cinco', 'casi', 'dir', 'per', 'xima', 'nar', 'anja', 'centr', 'litor', 'hoy', 'hor', 'gener', 'luego', 'cerr', 'acto', 'kilómetr', 'san', 'anuncian', 'regresaron', 'ayuda', 'largo', 'ves', 'coles', 'tar', 'ección', 'per', 'mayor', 'sobr', 'horas', 'tres', 'seis', 'tras', 'esar', 'negr', 'én', 'jó', 'km', 'caso', 'mid', 'eportó', 'mo', 'ec', 'ían', 'ga', 'utu', 'alfr', 'lucí', 'frí', 'aje', 'ea', 'si', 'ídeas', 'seguir', 'achas', 'destr', 'otr', 'bien', 'pronó', 'pu', 'dile', 'die', 'cuenta', 'nueva', 'además', 'altur', 'alta', 'negro', 'debido', 'nivel', 'meteor', 'santa', 'baja', 'noche', 'mientr', 'mismas', 'super', 'esentar', 'lunes', 'siguien', 'river', 'sinae', 'bí', 'ecibió', 'pér', 'beníte', 'portal tan', 'ñada', 'za', 'real', 'go', 'air', 'afectó', 'zos', 'metr', 'ho', 'ecla', 'eñ', 'tornad', 'cabe', 'bajo', 'partir', 'nie', 'met', 'fines', 'ada', 'miér', 'miér tendr', 'andí', 'efe', 'oed', 'or', 'vé', 'fi', 'cr', 'días', 'cifras', 'omedio', 'pa', 'va', 'ados', 'parte', 'hs', \n",
    "           'omedio', 'cialmente', 'igual', 'sinó', 'habla', 'occide', 'cuanto', 'or', 'continuar', 'días', 'vivirá', 'llegado vientos', 'vivirá invierno', 'habr', 'menor', 'sw', 'tan', 'ados', 'ava', 'energí', 'cubrir', 'pesar', 'ocer', 'cr', 'pudo', 'encia', 'eje', 'salvo', 'sinó', 'resto', 'después', 'ano', 'cer', 'nue', 'junto', 'llegado', 'gía', 'ahí', 'debe', 'llo', 'apr', 'fas', 'etir', 'pa', 'jar', 'face', 'energí', 'ente', 'va', 'ados', 'men', 'égimen', 'agr', 'egión', 'mejor', 'ahora', 'pró', 'meteorologí', 'meteoroló', 'abunda', 'aviso', 'lar', 'apagó', 'diferentes', 'frão', 'aunque', 'día', 'hacia', 'palmente', 'inter agr', 'gato', 'vierne', 'cuatr', 'egión', 'ahora', 'car', 'dv', 'urug', 'des', 'dãs', 'pró', 'meteorologí', 'meteoroló', 'incr', 'ven', 'otar', 'tener', 'vez', 'dar', 'alto', 'pro', 'lar', 'agr', 'égimen', 'coster', 'vén', 'monte', 'empie', 'volver', 'llue', 'cambia llue', 'vuelvan ecién', 'hecha chaparr', 'agencia ológicas', 'unión ruta', 'presentó', 'napoli', 'tendr magnitud', 'ambas puntas', 'onósticos muestr', 'once', 'siguientes', 'mismos', 'diez', 'misma', 'continú', 'eo', 'ta', 'the', 'asil', 'tando', 'pudiendo', 'segú', 'artigas acuar', 'manteniéndose cielo', 'formarse pasada', 'lugar otegidos', 'indicó', 'confusión gracias', 'pi', 'vias', 'ategidos eir', 'saneamient', 'rmicas', 'xtendió mediodía', 'yectiles asegur', 'can', 'fu', 'ello', 'vén', 'llegar', 'cubierto', 'vocó', 'ras', 'asil', 'eas', 'lino', 'ta', 'dad', 'dier', 'ega', 'can', 'tando', 'estan', 'misma', 'seguirán', 'ecién', 'puede', 'arse', 'onómico', 'ayer', 'vier', 'uelven', 'últimas', 'entras cnn', 'llegar', 'einta', 'alguna', 'ximo', 'allí', 'siete', 'lle', 'cepción', 'embar', 'cuales', 'ollo', 'oyo', 'siete', 'den', 'nor', 'estima', 'tendr', 'dañ', 'qui', 'embr', 'agrometeorolã³gicas', 'danos', 'ológicas encuentr', 'onósticos ológicos', 'ológico', 'orio', 'especí', 'nor', 'solo', 'ubicar', 'siguen', 'ubo mucha', 'nuboso perãodos', 'ado', 'dãa', 'lucía visitó', 'empi naranjas', 'continua', 'estara', 'coor', 'villa serr', 'guien', 'gu', 'entos egún', 'buena', 'anuncia', 'desmejor ando', 'érica', 'obables', 'eporte', 'abu', 'ecibir', 'disipa', 'ademã', 'tempor', 'entra', 'eclamos', 'eir', 'supone', 'nuestr', 'eather', 'llega', 'mismo', 'distintos', 'comité', 'email', 'gencias', 'treinta', 'rocha', 'inicia', 'retiro', 'nueve', 'niñ', 'montevi', 'surge', 'encontr adultos', 'subterr', 'evacuad', 'enajes', 'hechos', 'ológicas encuentr', 'tomen', 'eciben atención', 'queremos', 'villa serr', 'llamado', 'via', 'signi', 'aplicó', 'despistó', 'lindo maldo', 'aler marilla', 'ejér cito', 'penitente villa', 'xistentes', 'depresió prevé', 'ultimas', 'pass', 'habra', 'gran', 'viembr', 'vía', 'egiones', 'ando', 'ver', 'registró', 'aún', 'pueden', 'hacer papelone', 'pintos', 'suaves', 'esperan', 'varios', 'fuertes', 'predecir', 'fuente', 'pasos inundacione', 'pasado', 'página', 'cec', 'hicieron', 'edó', \n",
    "           'lugo flor', 'doming', 'ativo etorno', 'debajo', 'encuentr discr', 'epasando seguridad', 'pueda', 'mucha', 'edominante', 'emonta rosa', 'ejér cito', 'mencionó', 'presunto', 'todavía hogar', 'manana', 'podrían alcanzar', 'llamados', 'vigencia', 'prevén', 'consider', 'espectivamente', 'vadas', 'cerrados', 'caídos', 'dieron positivo', 'informar', 'ativo etorno', 'inter', 'trece', 'cómo', 'mes empi', 'encuentra', 'vuelven', 'edujo', 'rural cámara', 'todavía hogar', 'recorrerá afectar', 'ativo etorno', 'doming', 'falta', 'zclada', 'sacude', 'tareas limpiez', 'pago', 'madrugada menos', 'ganismo', 'realiza', 'asociadas', 'aumentó', 'artigas', 'último', 'caído', 'coordinador', 'varias', 'voladura', 'recibilas', 'cortadas', 'cuyas', 'ídas', 'habilitar', 'incrementará', 'especialmente', 'mw anco', 'labor', 'anuncio', 'diciemb', 'mañanna martes', 'intensan', 'pai', 'especialmente', 'xterior evitar', 'hacer papelone', 'cado', 'ecientes', 'saber', 'superior', 'ecientes', 'ecomienda', 'seguirá', 'oblemas', 'villa serr', 'buen', 'comentó', 'todavía hogar', 'anterior', 'semana', 'gues eciben', 'esuntamente', 'pai', 'tormen', 'junta', 'balance', ' perros dieron', '']\n",
    "\n",
    "#Eliminar stopwords\n",
    "stop = stopwords.words('spanish')\n",
    "stop.extend (agregar)\n",
    "df['parsed'] = df['clean_text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['parsed'] = df['parsed'].apply(tuple)\n",
    "df['parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       iglesia anglicana organizaciones gubernamental...\n",
       "1       iglesia anglicana organizaciones gubernamental...\n",
       "2       director salud intendencia personas refugios e...\n",
       "3       director salud intendencia personas refugios e...\n",
       "4       director salud intendencia personas refugios e...\n",
       "                              ...                        \n",
       "1524                                    sacrificio perros\n",
       "1525                 salud pública confirmó visceral niño\n",
       "1526                            confirmó segundo visceral\n",
       "1527                       suspendió emergencia sanitaria\n",
       "1528            sostienen msp exterminio perros respuesta\n",
       "Name: parsed, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['parsed']= df['parsed'].apply(' '.join)\n",
    "df['parsed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scattertext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurar el corpus para scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (iglesia, anglicana, organizaciones, gubername...\n",
       "1       (iglesia, anglicana, organizaciones, gubername...\n",
       "2       (director, salud, intendencia, personas, refug...\n",
       "3       (director, salud, intendencia, personas, refug...\n",
       "4       (director, salud, intendencia, personas, refug...\n",
       "                              ...                        \n",
       "1524                                 (sacrificio, perros)\n",
       "1525           (salud, pública, confirmó, visceral, niño)\n",
       "1526                        (confirmó, segundo, visceral)\n",
       "1527                   (suspendió, emergencia, sanitaria)\n",
       "1528      (sostienen, msp, exterminio, perros, respuesta)\n",
       "Name: parsed_1, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('es_core_news_sm')\n",
    "df['parsed_1']=df['parsed'].apply(str)\n",
    "df['parsed_1'] = df['parsed_1'].apply(nlp)\n",
    "df['parsed_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scattertext.ParsedCorpus.ParsedCorpus at 0x2575b148d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scattertext as st\n",
    "corpus = st.CorpusFromParsedDocuments(df, category_col='Category', parsed_col='parsed_1').build()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria=df['Category']\n",
    "colum_text=df['parsed_1']\n",
    "data=pd.DataFrame(zip(categoria, colum_text), columns=['CATEGORIA', 'TEXTO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contar valores de categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Count\n",
      "CATEGORIA\n",
      "Actores                    88\n",
      "efectos                   482\n",
      "enfermedades               73\n",
      "eventos meteorológicos    790\n",
      "respuestas                 96\n",
      "Name: TEXTO, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Document Count\")\n",
    "print(data.groupby('CATEGORIA')['TEXTO'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "cat1='Actores'\n",
    "cat2='efectos'\n",
    "cat3='eventos meteorológicos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalers.percentile_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462635"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category=cat1, #<------- modificable -------------->\n",
    "                                    category_name=cat2, #<------- modificable -------------->\n",
    "                                    not_category_name=cat3, #<------- modificable -------------->\n",
    "                                    width_in_pixels=1000, #<------- modificable -------------->\n",
    "                                    minimum_term_frequency=0, #<------- modificable -------------->\n",
    "                                    term_scorer=st.RankDifference(),\n",
    "                                    transform=st.Scalers.percentile_dense,\n",
    "                                    metadata=data['CATEGORIA'])\n",
    "file_name = path +'Scalers.percentile_dense.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalers_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478847"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category=cat1, #<------- modificable -------------->\n",
    "                                    category_name=cat2, #<------- modificable -------------->\n",
    "                                    not_category_name=cat3, #<------- modificable -------------->\n",
    "                                    width_in_pixels=1000, #<------- modificable -------------->\n",
    "                                    minimum_term_frequency=0, #<------- modificable -------------->\n",
    "                                    transform=st.Scalers.scale,\n",
    "                                    metadata=data['CATEGORIA'])\n",
    "file_name = path +'Scalers_scale.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalers_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459689"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scattertext import SampleCorpora, PhraseMachinePhrases, dense_rank, RankDifference, AssociationCompactor, produce_scattertext_explorer\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category=cat1, #<------- modificable -------------->\n",
    "                                    category_name=cat2, #<------- modificable -------------->\n",
    "                                    not_category_name=cat3, #<------- modificable -------------->\n",
    "                                    width_in_pixels=1000, #<------- modificable -------------->\n",
    "                                    minimum_term_frequency=0, #<------- modificable -------------->\n",
    "                                    transform=st.Scalers.percentile,\n",
    "                                    metadata=data['CATEGORIA'])\n",
    "file_name = path + 'Scalers_percentile.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459689"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from scattertext import SampleCorpora, word_similarity_explorer_gensim, Word2VecFromParsedCorpus\n",
    "model = word2vec.Word2Vec(size=300, #<------- modificable -------------->\n",
    "                          alpha=0.025, #<------- modificable -------------->\n",
    "                          window=5, #<------- modificable -------------->\n",
    "                          min_count=5, #<------- modificable -------------->\n",
    "                          max_vocab_size=None, #<------- modificable -------------->\n",
    "                          sample=0, #<------- modificable -------------->\n",
    "                          seed=1, #<------- modificable -------------->\n",
    "                          workers=1, #<------- modificable -------------->\n",
    "                          min_alpha=0.0001, #<------- modificable -------------->\n",
    "                          sg=1, #<------- modificable -------------->\n",
    "                          hs=1, #<------- modificable -------------->\n",
    "                          negative=0, #<------- modificable -------------->\n",
    "                          cbow_mean=0, #<------- modificable -------------->\n",
    "                          iter=1, #<------- modificable -------------->\n",
    "                          null_word=0, #<------- modificable -------------->\n",
    "                          trim_rule=None, #<------- modificable -------------->\n",
    "                          sorted_vocab=1) #<------- modificable -------------->\n",
    "html3 = word_similarity_explorer_gensim(corpus, #<------- modificable -------------->\n",
    "                                       category=cat1, #<------- modificable -------------->\n",
    "                                       category_name=cat2, #<------- modificable -------------->\n",
    "                                       not_category_name=cat3, #<------- modificable -------------->\n",
    "                                       target_term='alerta', #<------- modificable -------------->\n",
    "                                       minimum_term_frequency=0, #<------- modificable -------------->\n",
    "                                       pmi_threshold_coefficient=4, #<------- modificable -------------->\n",
    "                                       width_in_pixels=1000, #<------- modificable -------------->\n",
    "                                       metadata=data['CATEGORIA'],\n",
    "                                       word2vec=Word2VecFromParsedCorpus(corpus, model).train(),\n",
    "                                       max_p_val=0.05, #<------- modificable -------------->\n",
    "                                       save_svg_button=True) #<------- modificable -------------->\n",
    "open(path + 'Gensim_similarity.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization_Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrador\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:512: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0, tolerance: 0.0\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\users\\administrador\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scattertext\\Scalers.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1268761"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from scattertext import sparse_explorer\n",
    "html = sparse_explorer(corpus,\n",
    "                        category=cat1, #<------- modificable -------------->\n",
    "                        category_name=cat2, #<------- modificable -------------->\n",
    "                        not_category_name=cat3, #<------- modificable -------------->\n",
    "                        scores = corpus.get_regression_coefs('CATEGORIA', Lasso(max_iter=10000)), #<------- modificable -------------->\n",
    "                        minimum_term_frequency=0, #<------- modificable -------------->\n",
    "                        pmi_threshold_coefficient=4, #<------- modificable -------------->\n",
    "                        width_in_pixels=1000, #<------- modificable -------------->\n",
    "                        metadata=data['CATEGORIA'])\n",
    "open(path +'Visualization_Sparse.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec_modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616549"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import umap\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "html = st.produce_projection_explorer(corpus,\n",
    "                                      word2vec_model=Word2Vec(size=100, window=5, min_count=10, workers=4), #<------- modificable -------------->\n",
    "                                      projection_model=umap.UMAP(min_dist=0.5, metric='cosine'), #<------- modificable -------------->\n",
    "                                      category=cat1,#<------- modificable -------------->\n",
    "                                      category_name=cat2, #<------- modificable -------------->\n",
    "                                      not_category_name=cat3, #<------- modificable -------------->\n",
    "                                      metadata=data)\n",
    "open(path + 'Word2vec_modele.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotten_fresh_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496360"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category=cat1, #<------- modificable -------------->\n",
    "    not_categories=['efectos'], #<------- modificable -------------->\n",
    "    sort_by_dist=False, #<------- modificable -------------->\n",
    "    metadata=data['CATEGORIA'], #<------- modificable -------------->\n",
    "    term_scorer=st.RankDifference())\n",
    "    \n",
    "file_name = path + 'Rotten_fresh_st.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalers.dense_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462674"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category=cat1, #<------- modificable -------------->\n",
    "                                    category_name=cat2, #<------- modificable -------------->\n",
    "                                    not_category_name=cat3, #<------- modificable -------------->\n",
    "                                    width_in_pixels=1000, #<------- modificable -------------->\n",
    "                                    minimum_term_frequency=0, #<------- modificable -------------->\n",
    "                                    term_scorer=st.RankDifference(),\n",
    "                                    transform=st.Scalers.dense_rank,\n",
    "                                    metadata=data['CATEGORIA'])\n",
    "file_name = path + 'Scalers.dense_rank.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
